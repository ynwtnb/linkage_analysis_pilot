{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Randomize data**\n",
    "\n",
    "This script is for randomizing data to enable blinded analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generate random number for each condition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "assignment_save_dir = '../data/assignment/'\n",
    "assignment_save_file = 'assignment.txt'\n",
    "mindware_dir = '../data/mindware_processed/'\n",
    "data_dir = '../data/preprocessed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditions and numbers to assign\n",
    "conditions = [\"positive\", \"negative\", \"neutral\"]\n",
    "numbers = [1, 2, 3]\n",
    "\n",
    "# randomly shuffle the numbers\n",
    "random.shuffle(numbers)\n",
    "\n",
    "# assign the randomly shuffled numbers to the conditions\n",
    "random_assignment = dict(zip(conditions, numbers))\n",
    "\n",
    "# save the random assignment to a file\n",
    "if  not os.path.exists(assignment_save_dir):\n",
    "    os.makedirs(assignment_save_dir)\n",
    "with open(assignment_save_dir + assignment_save_file, 'w') as f:\n",
    "    for key in random_assignment.keys():\n",
    "        f.write(\"%s,%s\\n\"%(key, random_assignment[key]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load Mindware IBI data and randomize file names**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mindware_ibi(df: pd.DataFrame) -> tuple[np.ndarray, int]:\n",
    "    # List to store the IBI values\n",
    "    ibi_array = []\n",
    "    # Offset of the first IBI\n",
    "    first_ibi_offset = None\n",
    "\n",
    "    # Process each segment\n",
    "    for col in df.columns:\n",
    "        # Drop NaN values and get the segment data\n",
    "        segment_data = df[col].dropna().values\n",
    "\n",
    "        if len(segment_data) == 0:\n",
    "            continue\n",
    "        \n",
    "        # The first and last values are the start and end offsets\n",
    "        start_offset = segment_data[0]\n",
    "        end_offset = segment_data[-1]\n",
    "        \n",
    "        # Extract actual IBIs (excluding the start and end offsets)\n",
    "        true_ibi = segment_data[1:-1] if len(segment_data) > 2 else []\n",
    "\n",
    "        # Add the start offset to the previous segment's last offset to calculate IBI\n",
    "        if len(ibi_array) > 0:\n",
    "            ibi_array[-1] += start_offset\n",
    "        else:\n",
    "            first_ibi_offset = int(start_offset)\n",
    "\n",
    "        # Add actual IBIs to the list\n",
    "        ibi_array.extend(true_ibi)\n",
    "        \n",
    "        # Add the end offset to the list\n",
    "        ibi_array.append(end_offset)\n",
    "\n",
    "    ibi_array = np.array(ibi_array)\n",
    "    # Remove the very last IBI\n",
    "    ibi_array = ibi_array[:-1]\n",
    "    \n",
    "    return ibi_array, first_ibi_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mindware_files = os.listdir(mindware_dir)\n",
    "mindware_files = [f for f in mindware_files if 'HRV Analysis' in f]\n",
    "preprocessed_files = os.listdir(data_dir)\n",
    "\n",
    "for condition in conditions:\n",
    "    mindware_files_condition = [f for f in mindware_files if condition in f]\n",
    "    preprocessed_files_condition = [f for f in preprocessed_files if condition in f]\n",
    "    mw_file_NN = [f for f in mindware_files_condition if 'NN' in f][0]\n",
    "    mw_file_YW = [f for f in mindware_files_condition if 'NN' not in f][0]\n",
    "    preprocessed_file_NN = [f for f in preprocessed_files_condition if 'NN' in f][0]\n",
    "    preprocessed_file_YW = [f for f in preprocessed_files_condition if 'NN' not in f][0]\n",
    "    condition_no = random_assignment[condition]\n",
    "\n",
    "    mw_df_NN = pd.read_excel(mindware_dir + mw_file_NN, sheet_name='IBI')\n",
    "    mw_df_YW = pd.read_excel(mindware_dir + mw_file_YW, sheet_name='IBI')\n",
    "    ibi_NN, first_ibi_offset_NN = process_mindware_ibi(mw_df_NN)\n",
    "    ibi_YW, first_ibi_offset_YW = process_mindware_ibi(mw_df_YW)\n",
    "    elapsed_time_NN = first_ibi_offset_NN + np.cumsum(ibi_NN)\n",
    "    elapsed_time_YW = first_ibi_offset_YW + np.cumsum(ibi_YW)\n",
    "\n",
    "    preprocessed_df_NN = pd.read_csv(data_dir + preprocessed_file_NN)\n",
    "    preprocessed_df_YW = pd.read_csv(data_dir + preprocessed_file_YW)\n",
    "    preprocessed_df_NN['timestamp'] = pd.to_datetime(preprocessed_df_NN['timestamp'])\n",
    "    preprocessed_df_YW['timestamp'] = pd.to_datetime(preprocessed_df_YW['timestamp'])\n",
    "    first_time_NN = preprocessed_df_NN['timestamp'].iloc[0]\n",
    "    first_time_YW = preprocessed_df_YW['timestamp'].iloc[0]\n",
    "    last_time_NN = preprocessed_df_NN['timestamp'].iloc[-1]\n",
    "    last_time_YW = preprocessed_df_YW['timestamp'].iloc[-1]\n",
    "\n",
    "    mw_timestamps_NN = [first_time_NN + pd.Timedelta(milliseconds=t) for t in elapsed_time_NN]\n",
    "    mw_timestamps_YW = [first_time_YW + pd.Timedelta(milliseconds=t) for t in elapsed_time_YW]\n",
    "\n",
    "    ibi_df_NN = pd.DataFrame({'IBI': ibi_NN, 'timestamp': mw_timestamps_NN})\n",
    "    ibi_df_YW = pd.DataFrame({'IBI': ibi_YW, 'timestamp': mw_timestamps_YW})\n",
    "\n",
    "    # Align time range\n",
    "    first_timestamp = max(first_time_NN, first_time_YW)\n",
    "    last_timestamp = min(last_time_NN, last_time_YW)\n",
    "    ibi_df_NN = ibi_df_NN.loc[(ibi_df_NN['timestamp'] >= first_timestamp) & (ibi_df_NN['timestamp'] <= last_timestamp)].reset_index(drop=True)\n",
    "    ibi_df_YW = ibi_df_YW.loc[(ibi_df_YW['timestamp'] >= first_timestamp) & (ibi_df_YW['timestamp'] <= last_timestamp)].reset_index(drop=True)\n",
    "    preprocessed_df_NN = preprocessed_df_NN.loc[(preprocessed_df_NN['timestamp'] >= first_timestamp) & (preprocessed_df_NN['timestamp'] <= last_timestamp)].reset_index(drop=True)\n",
    "    preprocessed_df_YW = preprocessed_df_YW.loc[(preprocessed_df_YW['timestamp'] >= first_timestamp) & (preprocessed_df_YW['timestamp'] <= last_timestamp)].reset_index(drop=True)\n",
    "\n",
    "    preprocessed_df_NN['time'] = (preprocessed_df_NN['timestamp'] - first_timestamp).dt.total_seconds() * 1000\n",
    "    preprocessed_df_YW['time'] = (preprocessed_df_YW['timestamp'] - first_timestamp).dt.total_seconds() * 1000\n",
    "    preprocessed_df_NN = preprocessed_df_NN.drop(columns=['timestamp'])\n",
    "    preprocessed_df_YW = preprocessed_df_YW.drop(columns=['timestamp'])\n",
    "\n",
    "    ibi_df_NN['time'] = (ibi_df_NN['timestamp'] - first_timestamp).dt.total_seconds() * 1000\n",
    "    ibi_df_YW['time'] = (ibi_df_YW['timestamp'] - first_timestamp).dt.total_seconds() * 1000\n",
    "    ibi_df_NN = ibi_df_NN.drop(columns=['timestamp'])\n",
    "    ibi_df_YW = ibi_df_YW.drop(columns=['timestamp'])\n",
    "    \n",
    "    ibi_df_NN.to_csv(f'{mindware_dir}mindware_IBI_NN_{condition_no}.csv', index=False)\n",
    "    ibi_df_YW.to_csv(f'{mindware_dir}mindware_IBI_YW_{condition_no}.csv', index=False)\n",
    "\n",
    "    preprocessed_df_NN.to_csv(f'{data_dir}preprocessed_NN_{condition_no}.csv', index=False)\n",
    "    preprocessed_df_YW.to_csv(f'{data_dir}preprocessed_YW_{condition_no}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
